pub mod event_handler;
pub mod managers;
pub mod storage;

use crate::storage::types::BlockIndexingStatus;
use anyhow::Result;
use ark_starknet::client::StarknetClient;
use event_handler::EventHandler;
use log::{info, trace};
use managers::{BlockManager, CollectionManager, EventManager, PendingBlockData, TokenManager};
use starknet::core::types::*;
use std::sync::Arc;
use storage::types::{ContractType, StorageError};
use storage::Storage;
use tokio::sync::RwLock as AsyncRwLock;
use tokio::time::{self, Duration};
use tracing::{span, Level};
use tracing_subscriber::{fmt, layer::SubscriberExt, EnvFilter, Registry};

pub type IndexerResult<T> = Result<T, IndexerError>;

/// Generic errors for Pontos.
#[derive(Debug, thiserror::Error)]
pub enum IndexerError {
    #[error("Storage error occurred")]
    StorageError(StorageError),
    #[error("An error occurred")]
    Anyhow(String),
}

impl From<StorageError> for IndexerError {
    fn from(e: StorageError) -> Self {
        IndexerError::StorageError(e)
    }
}

impl From<anyhow::Error> for IndexerError {
    fn from(e: anyhow::Error) -> Self {
        IndexerError::Anyhow(e.to_string())
    }
}

pub struct PontosConfig {
    pub indexer_version: u64,
    pub indexer_identifier: String,
}

pub struct Pontos<S: Storage, C: StarknetClient, E: EventHandler> {
    client: Arc<C>,
    event_handler: Arc<E>,
    config: PontosConfig,
    block_manager: Arc<BlockManager<S>>,
    event_manager: Arc<EventManager<S>>,
    token_manager: Arc<TokenManager<S, C>>,
    collection_manager: Arc<AsyncRwLock<CollectionManager<S, C>>>,
    pending_cache: Arc<AsyncRwLock<PendingBlockData>>,
}

impl<S: Storage, C: StarknetClient, E: EventHandler + Send + Sync> Pontos<S, C, E> {
    ///
    pub fn new(
        client: Arc<C>,
        storage: Arc<S>,
        event_handler: Arc<E>,
        config: PontosConfig,
    ) -> Self {
        init_tracing();

        Pontos {
            config,
            client: Arc::clone(&client),
            event_handler: Arc::clone(&event_handler),
            block_manager: Arc::new(BlockManager::new(Arc::clone(&storage))),
            event_manager: Arc::new(EventManager::new(Arc::clone(&storage))),
            token_manager: Arc::new(TokenManager::new(Arc::clone(&storage), Arc::clone(&client))),
            // Collection manager has internal cache, so some functions are using `&mut self`.
            // For this reason, we must protect the write operations in order to share
            // the cache with any possible thread using `index_block_range` of this instance.
            collection_manager: Arc::new(AsyncRwLock::new(CollectionManager::new(
                Arc::clone(&storage),
                Arc::clone(&client),
            ))),
            pending_cache: Arc::new(AsyncRwLock::new(PendingBlockData::new())),
        }
    }

    /// Starts a loop to only index the pending block.
    pub async fn index_pending(&self) -> IndexerResult<()> {
        // TODO: Here we have two choices, we can send a special value and replace it
        // later. Or we can take the risk to simply increment the value
        // from the last block. But that may conduct to invalid data
        // if the sequencer changes the number for any reason.
        // But we need a valid u64 to insert info in the database.
        let mut block_number = u64::MAX;
        let mut is_first = true;

        loop {
            let mut cache = self.pending_cache.write().await;

            let (ts, txs) = self
                .client
                .block_txs_hashes(BlockId::Tag(BlockTag::Pending))
                .await?;

            log::info!("Pending block {} with {} txs", ts, txs.len());

            // If the timestamp is different from the previous loop,
            // we must first ensure we've fetched and processed all the transactions
            // of the previous pending block, which is now the "Latest".
            if ts != cache.timestamp && !is_first {
                // Get the latest block number, generated by the sequencer, which is
                // the one we just processed.
                block_number = self.client.block_number().await?;
                let (latest_ts, txs) = self
                    .client
                    .block_txs_hashes(BlockId::Tag(BlockTag::Latest))
                    .await?;
                // We have 3 min here to process everything. As it's done every second,
                // it should be totally fine.
                // In the future, when starknet will have few seconds per block,
                // this code will no longer be useful as the UX will be better
                // without pending state.

                for tx_hash in txs {
                    if cache.is_tx_processed(&tx_hash) {
                        continue;
                    } else {
                        let events = self.client.events_from_tx_receipt(tx_hash).await?;
                        self.process_events(events, block_number, cache.timestamp)
                            .await?;
                    }
                }

                // Notify about the change of block pending.
                // TODO: is this core function? Do we want to update directly?
                self.block_manager
                    .update_last_pending_block(block_number, latest_ts)
                    .await?;

                log::info!(
                    "Pending block {} is now latest block number #{}",
                    latest_ts,
                    block_number
                );
                // Update timestamp to the current pending and clear the txs to start
                // processing the new pending block.
                cache.timestamp = ts;
                cache.clear_tx_hashes();
                // Get back to pending default value.
                block_number = u64::MAX;
                is_first = false;
            }

            // Process pending txs, if not already processed.
            for tx_hash in txs {
                if cache.is_tx_processed(&tx_hash) {
                    continue;
                } else {
                    let events = self.client.events_from_tx_receipt(tx_hash).await?;
                    self.process_events(events, block_number, cache.timestamp)
                        .await?;
                }
            }

            // TODO: make this configurable?
            tokio::time::sleep(tokio::time::Duration::from_secs(1)).await;
        }
    }

    /// If "Latest" is used for the `to_block`,
    /// this function will only index the latest block
    /// that is not pending.
    /// If you use this on latest, be sure to don't have any
    /// other pontos instance running `index_pending` as you may
    /// deal with overlaps or at least check db registers first.
    pub async fn index_block_range(
        &self,
        from_block: BlockId,
        to_block: BlockId,
        do_force: bool,
    ) -> IndexerResult<()> {
        let is_head_of_chain = to_block == BlockId::Tag(BlockTag::Latest);
        log::debug!(
            "Indexing range: {:?} {:?} (head of chain: {}) (force: {})",
            from_block,
            to_block,
            is_head_of_chain,
            do_force,
        );

        let mut current_u64 = self.client.block_id_to_u64(&from_block).await?;
        let mut to_u64 = self.client.block_id_to_u64(&to_block).await?;

        loop {
            trace!("Indexing block range: {} {}", current_u64, to_u64);

            to_u64 = self
                .check_range(current_u64, to_u64, is_head_of_chain)
                .await;
            if current_u64 > to_u64 {
                continue;
            }

            if !self
                .block_manager
                .check_candidate(current_u64, self.config.indexer_version, do_force)
                .await
            {
                current_u64 += 1;
                continue;
            }

            self.event_handler.on_block_processing(current_u64).await;

            // Set block as pending
            self.block_manager
                .set_block_info(
                    current_u64,
                    self.config.indexer_version,
                    &self.config.indexer_identifier,
                    BlockIndexingStatus::Processing,
                )
                .await?;

            let block_ts = self.client.block_time(BlockId::Number(current_u64)).await?;

            let blocks_events = self
                .client
                .fetch_events(
                    BlockId::Number(current_u64),
                    BlockId::Number(current_u64),
                    self.event_manager.keys_selector(),
                )
                .await?;

            let total_events_count: usize = blocks_events.values().map(|events| events.len()).sum();
            info!(
                "âœ¨ Processing block {}. Total Events Count: {}",
                current_u64, total_events_count
            );

            for (_, events) in blocks_events {
                self.process_events(events, current_u64, block_ts).await?;
            }

            self.block_manager
                .set_block_info(
                    current_u64,
                    self.config.indexer_version,
                    &self.config.indexer_identifier,
                    BlockIndexingStatus::Terminated,
                )
                .await?;
            self.event_handler
                .on_terminated(current_u64, (current_u64 as f64 / to_u64 as f64) * 100.0)
                .await;

            current_u64 += 1;
        }
    }

    /// Inner function to process events.
    async fn process_events(
        &self,
        events: Vec<EmittedEvent>,
        block_number: u64,
        block_timestamp: u64,
    ) -> IndexerResult<()> {
        for e in events {
            let contract_address = e.from_address;

            let contract_type = match self
                .collection_manager
                .write()
                .await
                .identify_contract(contract_address, block_number)
                .await
            {
                Ok(info) => info,
                Err(e) => {
                    log::error!(
                        "Error while identifying contract {}: {:?}",
                        contract_address,
                        e
                    );
                    continue;
                }
            };

            if contract_type == ContractType::Other {
                continue;
            }

            let token_event = match self
                .event_manager
                .format_and_register_event(&e, contract_type, block_timestamp)
                .await
            {
                Ok(te) => te,
                Err(err) => {
                    log::error!("Error while registering event {:?}\n{:?}", err, e);
                    continue;
                }
            };

            match self
                .token_manager
                .format_and_register_token(&token_event)
                .await
            {
                Ok(()) => (),
                Err(err) => {
                    log::error!("Can't format token {:?}\ntevent: {:?}", err, token_event);
                    continue;
                }
            }
        }

        Ok(())
    }

    async fn check_range(&self, current: u64, to: u64, is_head_of_chain: bool) -> u64 {
        if current >= to {
            if !is_head_of_chain {
                // TODO: can print some stats here if necessary.
                info!("End of indexing block range");
                std::process::exit(0);
            }

            // TODO: make this duration configurable (DELAY_HEAD_OF_CHAIN).
            // But we are at HOC, so for now the block interval is 3 min.
            // However, we want the block as soon as it's mined.
            time::sleep(Duration::from_secs(1)).await;

            // Head of the chain requested -> check the last block and continue
            // indexing loop.
            self.client
                .block_number()
                .await
                .expect("Can't fetch last block number")
        } else {
            to
        }
    }
}

fn init_tracing() {
    // Initialize the LogTracer to convert `log` records to `tracing` events
    tracing_log::LogTracer::init().expect("Setting log tracer failed.");

    // Create the layers
    let env_filter = EnvFilter::from_default_env();
    let fmt_layer = fmt::layer();

    // Combine layers and set as global default
    let subscriber = Registry::default().with(env_filter).with(fmt_layer);

    tracing::subscriber::set_global_default(subscriber)
        .expect("Setting default subscriber failed.");

    let main_span = span!(Level::TRACE, "main");
    let _main_guard = main_span.enter();
}
